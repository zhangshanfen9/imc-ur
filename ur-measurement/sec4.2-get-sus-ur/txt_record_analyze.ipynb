{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_PATH = './output/'\n",
    "RESULT_PATH = './output/analyze/txt/'\n",
    "VIRUS_TOTAL_RESULT_PATH = '/Users/zhangshanfeng/data/hosting_platform_no_validation/22_11_17_txt_record/main_txt_ur_data/vt/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:55:28.003901Z",
     "end_time": "2023-09-10T09:55:28.019543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def cmd(command):\n",
    "    ans = os.popen(command).read()\n",
    "    return ans\n",
    "\n",
    "cmd('mkdir -p ' + RESULT_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:55:28.018990Z",
     "end_time": "2023-09-10T09:55:29.649972Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load TXT record\n",
    "ur_arr = []\n",
    "standard_arr = []\n",
    "\n",
    "load_list = [\n",
    "    [ur_arr, 'oversea_top_list.txt_TXT-thd-300.json'],\n",
    "    [standard_arr, 'get_standard_record-resolve_to_address.txt_TXT-thd-300.json'],\n",
    "]\n",
    "for litem in load_list:\n",
    "    arr = litem[0]\n",
    "\n",
    "    with open(DATA_PATH + 'result/' + litem[-1], 'r') as f:\n",
    "        for line in tqdm(f, desc=litem[-1]):\n",
    "            ns = re.search(r'\"name_server\":\"(.*?):53\"', line).group(1)\n",
    "\n",
    "            if '\"recursion_available\":true' in line:\n",
    "                RA_flag = True\n",
    "            else:\n",
    "                RA_flag = False\n",
    "\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                domain = obj['name']\n",
    "                answers = obj['data']['answers']\n",
    "                for item in answers:\n",
    "                    arr.append([ns, domain, item['ttl'], RA_flag, item['answer']])\n",
    "            except KeyError:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:55:29.648985Z",
     "end_time": "2023-09-10T09:55:30.083344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ur_txt = pd.DataFrame(ur_arr, columns=['nameserver', 'domain', 'ttl', 'RA_flag', 'rdata'])\n",
    "# ur_txt.to_csv(RESULT_PATH + 'ur_txt.csv')\n",
    "# ur_txt = pd.read_csv(RESULT_PATH + 'ur_txt.csv').drop(columns='Unnamed: 0')\n",
    "ur_txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:55:29.756563Z",
     "end_time": "2023-09-10T09:55:30.319847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "standard_txt = pd.DataFrame(standard_arr, columns=['nameserver', 'domain', 'ttl', 'RA_flag', 'rdata'])\n",
    "# # standard_txt.to_csv(RESULT_PATH + 'standard_txt.csv')\n",
    "# standard_txt = pd.read_csv(RESULT_PATH + 'standard_txt.csv')\n",
    "standard_txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:55:29.854535Z",
     "end_time": "2023-09-10T09:55:30.572945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mark public service standard record\n",
    "dry_standard_txt = standard_txt[['rdata']].drop_duplicates()\n",
    "dry_standard_txt.loc[:, 'standard'] = True\n",
    "all_ur_txt = pd.merge(ur_txt, dry_standard_txt, on=['rdata'], how='left').fillna(False)\n",
    "# all_ur_txt = all_ur_txt[all_ur_txt.standard == False].drop(columns='standard')\n",
    "all_ur_txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:57:40.365194Z",
     "end_time": "2023-09-10T09:57:40.448008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here, we omiited the code of comparing PDNS data."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:59:24.435080Z",
     "end_time": "2023-09-10T09:59:24.480556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove RA response\n",
    "# remove public service standard record\n",
    "abnormal_ur_txt = all_ur_txt[\n",
    "    (all_ur_txt.RA_flag == False) &\n",
    "    (all_ur_txt.standard == False)\n",
    "].drop_duplicates()\n",
    "abnormal_ur_txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-10T09:59:25.970590Z",
     "end_time": "2023-09-10T09:59:26.089086Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter protected ns\n",
    "protective_ns = set()\n",
    "with open(DATA_PATH + './detect_protecting_records/txt_check_protect.json', 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        if ',\"data\":{},' in line:\n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            status = obj['status']\n",
    "            if status != 'NOERROR':\n",
    "                continue\n",
    "            ns = re.search(r'\"resolver\":\"(.*?):53\"', line).group(1)\n",
    "            protective_ns.add(ns)\n",
    "        except KeyError:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_ur_txt.loc[:, 'protected'] = False\n",
    "all_ur_txt.loc[(all_ur_txt.nameserver.isin(protective_ns)), 'protected'] = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "abnormal_ur_txt = abnormal_ur_txt[~abnormal_ur_txt.nameserver.isin(protective_ns)]\n",
    "abnormal_ur_txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort known pattern TXT records\n",
    "patterns = list(pd.read_excel('./txt_pattern.xlsx').fillna('').values)\n",
    "def match_pattern(s):\n",
    "    c = l = 'unknown'\n",
    "    r = nr = '-'\n",
    "    for p in patterns:\n",
    "        mp = p[2][18:-2]\n",
    "        # print(mp)\n",
    "        if re.match(mp, s):\n",
    "            if p[3] != '':\n",
    "                mnp = p[3][18:-2]\n",
    "                if re.match(mnp, s):\n",
    "                    continue\n",
    "            c = p[0]\n",
    "            l = p[1]\n",
    "            r = p[2]\n",
    "            nr = p[3]\n",
    "            break\n",
    "    # print(c, l, r, nr)\n",
    "    return c, l, r, nr\n",
    "# match_pattern('facebook-domain-verification=39xu4jzl7roi7x0n93ldkxjiaarx50')\n",
    "abnormal_ur_txt['Category'], abnormal_ur_txt['Label'], abnormal_ur_txt['Regular Expression'], abnormal_ur_txt['NOT Regular Expression'] = zip(*abnormal_ur_txt['rdata'].apply(match_pattern))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_ur_txt['Category'], all_ur_txt['Label'], all_ur_txt['Regular Expression'], all_ur_txt['NOT Regular Expression'] = zip(*all_ur_txt['rdata'].apply(match_pattern))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "abnormal_ur_txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_ur_txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_statistic = abnormal_ur_txt.groupby(['Category', 'Label']).agg({'rdata': 'count'}).sort_values('rdata', ascending=False)\n",
    "label_statistic.to_csv(RESULT_PATH + 'txt_category.csv')\n",
    "label_statistic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for label in abnormal_ur_txt.Label.unique():\n",
    "    abnormal_ur_txt[abnormal_ur_txt.Label == label].to_csv(RESULT_PATH + 'label_details/' + label.replace(' ', '_') + '.csv', index=False)\n",
    "    abnormal_ur_txt[abnormal_ur_txt.Label == label][['rdata']].groupby('rdata').agg({'rdata': 'count'}).rename(columns={'rdata': 'count'}).sort_values(by='count', ascending=False).to_csv(RESULT_PATH + 'label_unique/' + label.replace(' ', '_') + '.csv')\n",
    "    abnormal_ur_txt[abnormal_ur_txt.Label == label][['nameserver', 'target', 'rdata']].drop_duplicates(keep='first').to_csv(RESULT_PATH + 'domain_ns_unique/' + label.replace(' ', '_') + '.csv', index=False)\n",
    "    abnormal_ur_txt[abnormal_ur_txt.Label == label][['target', 'nameserver']].drop_duplicates(keep='first').to_csv(RESULT_PATH + 'domain_ns_unique/' + label.replace(' ', '_') + '_no_details.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "def is_protect(ip):\n",
    "    try:\n",
    "        result = ipaddress.ip_address(ip)\n",
    "        if not result.is_global:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Measure related A records\n",
    "abnormal_ur_txt[['domain','nameserver']].to_csv('./middle/get_TXT_ur_related_targets.txt', index=False, header=False)\n",
    "cmd('./get_TXT_ur_related_a.sh')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tarr = []\n",
    "with open(DATA_PATH + './middle/txt_related_a.json') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            status = obj['status']\n",
    "            if status != 'NOERROR':\n",
    "                continue\n",
    "\n",
    "            domain = obj['name']\n",
    "            resolver = re.search('\"resolver\":\"(.*?):53\"', line).group(1)\n",
    "            for sitem in obj['data']['ipv4_addresses']:\n",
    "                try:\n",
    "                    if not is_protect(sitem):\n",
    "                        tarr.append([resolver, domain, sitem])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "                # map(add_arr_dict, ns_addresses, [ns_name, ]*len(ns_addresses))\n",
    "                # map(add_num_dict, ns_addresses)\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "related_a = pd.DataFrame(tarr, columns=['nameserver', 'target', 'ip_address'])\n",
    "related_a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unique IP address in A records related TXT\n",
    "related_a['ip_address'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "abnormal_ur_txt.to_csv(RESULT_PATH + 'abnormal_ur_txt.csv', index=False)\n",
    "abnormal_ur_txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract IP address in TXT records\n",
    "ip_regex = '\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}'\n",
    "import ipaddress\n",
    "def valid_ip(address):\n",
    "    try:\n",
    "        ipaddress.ip_address(address)\n",
    "        if address[-2:] == '.0' or is_protect(address):\n",
    "            return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "tarr = []\n",
    "def get_txt_address(s):\n",
    "    all_match = re.findall(ip_regex, s['rdata'])\n",
    "    for m in all_match:\n",
    "        if valid_ip(m):\n",
    "            tarr.append([s['nameserver'], s['target'], s['domain'], s['RA_flag'],s['standard'], s['rdata'], s['Category'], s['Label'], m])\n",
    "\n",
    "abnormal_ur_txt.apply(get_txt_address, axis=1)\n",
    "txt_ip = pd.DataFrame(tarr, columns=['nameserver', 'target', 'domain', 'RA_flag', 'standard', 'rdata', 'Category', 'Label', 'ip_address']).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "txt_ip.to_csv(RESULT_PATH + 'txt_ip.csv', index=False)\n",
    "txt_ip"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
